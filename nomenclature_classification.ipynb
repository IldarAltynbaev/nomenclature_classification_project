{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8721662,"sourceType":"datasetVersion","datasetId":5233625}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt \nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import mean_absolute_error\nfrom torch.utils.data import DataLoader, TensorDataset\nimport string\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport sklearn.metrics as metrics\nfrom IPython.display import clear_output\nimport re as re\n\ndevice = torch.device('cuda')\nRANDOM_SEED = 0\nEMBEDDING_DIM = 100\nHIDDEN_DIM = 100\nNUM_HIDDEN_LAYERS = 2\nLEARNING_RATE = 0.001\nNUM_EPOCH = 100\ntorch.manual_seed(RANDOM_SEED)\n\ndef apply_reg_ex(text):\n    matches = re.findall('[a-zа-яА-ЯA-Z0-9\\s]+', text)\n    res_str = ''\n    for each_str in matches:\n        res_str = res_str + each_str\n    return res_str\n\ndef copy_data_to_device(data, device):\n    if torch.is_tensor(data):\n        return data.to(device)\n    elif isinstance(data, (list, tuple)):\n        return [copy_data_to_device(elem, device) for elem in data]\n    raise ValueError('Недопустимый тип данных {}'.format(type(data)))\n    \n\ndef get_tokenized_tensor(income_x, income_y,char_dict, MAX_SEN_LENGHT,DF_LENGHT,class_dict):\n    res_tensor_train = torch.zeros([DF_LENGHT,MAX_SEN_LENGHT],dtype=int)\n    if income_y is not None:\n        res_tensor_labels = torch.zeros([DF_LENGHT],dtype=torch.long)\n    else: res_tensor_labels = None\n    for df_index in range(DF_LENGHT):\n        for index, each_char in enumerate(income_x.iloc[df_index].name_before):\n            res_tensor_train[df_index,index] = char_dict[each_char]\n        if income_y is not None:\n            res_tensor_labels[df_index] = income_y.iloc[df_index]-1\n    return res_tensor_train, res_tensor_labels  \n\nall_possible_chars = string.printable + 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя' + '№–…’«»—ø°±²∆і―'\n\ndf =pd.read_excel('/kaggle/input/bit-nom/norm.xlsx')\ndf = df.rename(columns={\"Наименование исходное\": \"name_before\", \n                        \"Наименование нормализованное\": \n                        \"name_after\", \n                        'Код':'code',\n                        'Класс':'class_nom'})\ndf = df.sample(frac=1) \ndf['name_before'] = df['name_before'].apply(apply_reg_ex)\n\nunique_classes = df.class_nom.unique()\nclass_dict = {}\nnumber = 1\nfor each_element in unique_classes:\n    class_dict[each_element] = number\n    number=number + 1\n\nchars_dict = {'padding':0}\nnum_char = 1\nfor each_char in all_possible_chars:\n    chars_dict[each_char] = num_char\n    num_char+=1\n\n\ndf.class_nom = df.class_nom.map(class_dict)\ndf.name_after = df.name_after.str.lower()\ndf.name_before = df.name_before.str.lower()\n\naggregated_df = df.groupby(['class_nom'],as_index=False).count()\ndf_x = df.drop(['class_nom'],axis=1)\ndf_y = df['class_nom'] \ntrain_x,test_x, train_y,test_y = train_test_split(df_x, df_y,test_size=0.2, random_state=RANDOM_SEED)   \n\nMAX_SEN_LENGHT = 246#max(df.name_before.str.len())\nDF_TRAIN_LENGHT = len(train_x)\nDF_TEST_LENGHT = len(test_x)\ntensor_x, tensor_y = get_tokenized_tensor(train_x, train_y ,chars_dict,MAX_SEN_LENGHT,DF_TRAIN_LENGHT,class_dict)\ntrain_dataset = TensorDataset(tensor_x, tensor_y)\ntrain_dataloader = DataLoader(train_dataset,batch_size=300,drop_last=True)          \n\nval_x, val_y = get_tokenized_tensor(test_x, test_y ,chars_dict,MAX_SEN_LENGHT,DF_TEST_LENGHT,class_dict)\n\n\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-06-24T15:47:25.266203Z","iopub.execute_input":"2024-06-24T15:47:25.266535Z","iopub.status.idle":"2024-06-24T15:47:31.883262Z","shell.execute_reply.started":"2024-06-24T15:47:25.266505Z","shell.execute_reply":"2024-06-24T15:47:31.882241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class StackedConv1d(nn.Module):\n    def __init__(self, features_num, layers_n=1, kernel_size=3, conv_layer=nn.Conv1d, dropout=0.0):\n        super().__init__()\n        layers = []\n        for _ in range(layers_n):\n            layers.append(nn.Sequential(\n                conv_layer(features_num, features_num, kernel_size, padding=kernel_size//2),\n                nn.Dropout(dropout),\n                nn.LeakyReLU()))\n        self.layers = nn.ModuleList(layers)\n    \n    def forward(self, x):\n        \"\"\"x - BatchSize x FeaturesNum x SequenceLen\"\"\"\n        for layer in self.layers:\n            x = x + layer(x)\n        return x\n    \nclass SingleTokenPOSTagger(nn.Module):\n    def __init__(self, vocab_size, labels_num, embedding_size=32, **kwargs):\n        super().__init__()\n        self.char_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n        self.backbone = StackedConv1d(embedding_size, **kwargs)\n        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n        self.out = nn.Linear(embedding_size, labels_num)\n        self.labels_num = labels_num\n    \n    def forward(self, tokens):\n        \"\"\"tokens - BatchSize x MaxSentenceLen x MaxTokenLen\"\"\"\n        batch_size, max_token_len = tokens.shape\n        tokens_flat = tokens.view(batch_size , max_token_len)\n        \n        char_embeddings = self.char_embeddings(tokens_flat)  # BatchSize*MaxSentenceLen x MaxTokenLen x EmbSize\n        char_embeddings = char_embeddings.permute(0, 2, 1)  # BatchSize*MaxSentenceLen x EmbSize x MaxTokenLen\n        \n        features = self.backbone(char_embeddings)\n        \n        global_features = self.global_pooling(features).squeeze(-1)  # BatchSize*MaxSentenceLen x EmbSize\n        \n        logits_flat = self.out(global_features)  # BatchSize*MaxSentenceLen x LabelsNum\n        #logits = logits_flat.view(batch_size, max_sent_len, self.labels_num)  # BatchSize x MaxSentenceLen x LabelsNum\n        #logits = logits.permute(0, 2, 1)  # BatchSize x LabelsNum x MaxSentenceLen\n        return logits_flat\n    \ndef get_key(val):\n   \n    for key, value in class_dict.items():\n        if (val+1) == value:\n            return key\n \n    return \"key doesn't exist\"\n      ","metadata":{"execution":{"iopub.status.busy":"2024-06-24T15:47:31.892119Z","iopub.execute_input":"2024-06-24T15:47:31.892532Z","iopub.status.idle":"2024-06-24T15:47:31.907247Z","shell.execute_reply.started":"2024-06-24T15:47:31.892504Z","shell.execute_reply":"2024-06-24T15:47:31.906227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SingleTokenPOSTagger(len(chars_dict), len(class_dict), embedding_size=64, layers_n=3, kernel_size=3, dropout=0.3)\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\nloss_function = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-06-24T15:47:31.908365Z","iopub.execute_input":"2024-06-24T15:47:31.908718Z","iopub.status.idle":"2024-06-24T15:47:33.261035Z","shell.execute_reply.started":"2024-06-24T15:47:31.908686Z","shell.execute_reply":"2024-06-24T15:47:33.260070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_metrics(model,\n                    tensor_x,\n                    tensor_y,\n                    macro_precision_history,\n                    macro_recall_history,\n                    macro_f1score_history):\n    model.eval()\n    train_pred = model(tensor_x)  \n    train_loss = F.cross_entropy(torch.tensor(train_pred),\n                             torch.tensor(tensor_y))\n    #print('Среднее значение функции потерь на обучении', float(train_loss))\n    results = metrics.classification_report(tensor_y.view(-1).cpu(), train_pred.argmax(1).reshape(-1).cpu(), \\\n                                            output_dict=True,\\\n                                            target_names=class_dict,)\n    \n    print(metrics.classification_report(tensor_y.view(-1).cpu(), train_pred.argmax(1).reshape(-1).cpu(),\n                                            target_names=class_dict))\n    \n\n    \n    macro_precision_history.append(results['macro avg']['precision'])\n    macro_recall_history.append(results['macro avg']['recall'])\n    macro_f1score_history.append(results['macro avg']['f1-score'])\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-24T15:47:33.262280Z","iopub.execute_input":"2024-06-24T15:47:33.262695Z","iopub.status.idle":"2024-06-24T15:47:33.270492Z","shell.execute_reply.started":"2024-06-24T15:47:33.262669Z","shell.execute_reply":"2024-06-24T15:47:33.269630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"macro_precision_history_train = []\nmacro_recall_history_train = []\nmacro_f1score_history_train = []\nmacro_precision_history_val = []\nmacro_recall_history_val = []\nmacro_f1score_history_val = []\nepochs_history = []\n\nfor i in range(NUM_EPOCH):\n    model.train()\n    model.to(device)\n\n    for index, (inputs, labels) in enumerate(train_dataloader):\n        \n        inputs = copy_data_to_device(inputs, device)\n        labels = copy_data_to_device(labels, device)\n\n        #inputs = inputs.permute(1,0)\n        preds = model(inputs) \n        #_, predicted_labels = torch.max(preds, 1)\n        #loss_value = loss_function(preds, labels)\n        loss = loss_function(preds, labels)\n        optimizer.zero_grad()\n        #prec_score = metrics.precision_score(preds.argmax(dim=1).detach().numpy(), \\\n        #                                      labels.argmax(dim=1).detach().numpy(),average='macro')\n        \n        #rec_score = metrics.recall_score(preds.argmax(dim=1).detach().numpy(), \\\n        #                                      labels.argmax(dim=1).detach().numpy(),average='macro')\n        #print('Epoch ' + str(i) + ' index ' + str(index) + ' ' + str(loss.item()))\n        #print(prec_score)\n        #print(rec_score)\n        loss.backward()\n        optimizer.step()\n    \n    tensor_x = copy_data_to_device(tensor_x, device)\n    tensor_y = copy_data_to_device(tensor_y, device)\n    val_x = copy_data_to_device(val_x, device)\n    val_y = copy_data_to_device(val_y, device)\n    \n    clear_output()\n    evaluate_metrics(model, \n                     tensor_x,\n                     tensor_y,\n                     macro_precision_history_train,\n                     macro_recall_history_train,\n                     macro_f1score_history_train)\n    \n    evaluate_metrics(model, \n                     val_x,\n                     val_y,\n                     macro_precision_history_val,\n                     macro_recall_history_val,\n                     macro_f1score_history_val)\n\n    epochs_history.append(i)\n  \n    plt.plot(epochs_history, macro_precision_history_train,label='Train')\n    plt.plot(epochs_history, macro_precision_history_val,label='Val')\n    plt.xlabel('epochs')\n    plt.ylabel('macro_precision')\n    plt.show()\n\n    plt.plot(epochs_history, macro_recall_history_train,label='Train')\n    plt.plot(epochs_history, macro_recall_history_val,label = 'Val')\n    plt.xlabel('epochs')\n    plt.ylabel('macro_recall')\n    plt.show()\n\n    plt.plot(epochs_history, macro_f1score_history_train,label = 'Train')\n    plt.plot(epochs_history, macro_f1score_history_val,label = 'Val')\n    plt.xlabel('epochs')\n    plt.ylabel('macro_f1_score')\n    plt.show()\n \n    print()\n   ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-24T15:47:33.273593Z","iopub.execute_input":"2024-06-24T15:47:33.273959Z","iopub.status.idle":"2024-06-24T15:49:50.608532Z","shell.execute_reply.started":"2024-06-24T15:47:33.273928Z","shell.execute_reply":"2024-06-24T15:49:50.607619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_excel('/kaggle/input/bit-nom/norm.xlsx',sheet_name = 'Грязные данные для классификаци')\ntest_df = test_df.rename(columns={\"Наименование исходное\": \"name_before\"})\ntest_df.name_before = test_df.name_before.str.lower()\ntest_df['name_before'] = test_df['name_before'].apply(apply_reg_ex)\ntest_df = test_df.sample(frac=1) \ntest_tensor, _ = get_tokenized_tensor(test_df, None ,chars_dict,MAX_SEN_LENGHT,len(test_df),class_dict)\nmodel.eval()\ntest_tensor = copy_data_to_device(test_tensor, device)\ntest_preds = model(test_tensor)\ntest_preds = test_preds.argmax(dim=1).cpu().detach().numpy() \nres_pd = pd.DataFrame(test_preds)\nres_pd = res_pd.rename(columns={0: \"class_nom\"})","metadata":{"execution":{"iopub.status.busy":"2024-06-24T15:59:16.245151Z","iopub.execute_input":"2024-06-24T15:59:16.245806Z","iopub.status.idle":"2024-06-24T15:59:22.671653Z","shell.execute_reply.started":"2024-06-24T15:59:16.245775Z","shell.execute_reply":"2024-06-24T15:59:22.670602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2024-06-24T15:59:23.939738Z","iopub.execute_input":"2024-06-24T15:59:23.940629Z","iopub.status.idle":"2024-06-24T15:59:23.951071Z","shell.execute_reply.started":"2024-06-24T15:59:23.940590Z","shell.execute_reply":"2024-06-24T15:59:23.950164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_pd = res_pd.class_nom.apply(get_key)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T15:59:29.166621Z","iopub.execute_input":"2024-06-24T15:59:29.167446Z","iopub.status.idle":"2024-06-24T15:59:29.193708Z","shell.execute_reply.started":"2024-06-24T15:59:29.167413Z","shell.execute_reply":"2024-06-24T15:59:29.192761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv(\"output1.xlsx\")  \nres_pd.to_csv(\"output2.xlsx\")  ","metadata":{"execution":{"iopub.status.busy":"2024-06-24T15:59:31.417850Z","iopub.execute_input":"2024-06-24T15:59:31.418210Z","iopub.status.idle":"2024-06-24T15:59:31.516983Z","shell.execute_reply.started":"2024-06-24T15:59:31.418183Z","shell.execute_reply":"2024-06-24T15:59:31.515996Z"},"trusted":true},"execution_count":null,"outputs":[]}]}